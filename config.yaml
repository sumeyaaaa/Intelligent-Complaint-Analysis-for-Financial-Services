# config.yaml
data:
  # Path to the input data file
  csv_path: "data/clean/complaints_clean.csv"

processing:
  sample_size: null
  chunk_size: 300
  chunk_overlap: 20
  batch_size: 1000

embedding:
  # You are correctly using the 'base' model
  model_name: "BAAI/bge-base-en-v1.5"

output:
   index_path:"data/vector_store11/index_bge_base_300_20.faiss"
   meta_path:"data/vector_store11/meta_bge_base_300_20.csv"
  
retrieval:
  k: 5
reranker:
  model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  k: 3 # You can use a different k for re-ranking
llm:
  model_name: "google/flan-t5-large"
  max_new_tokens: 256